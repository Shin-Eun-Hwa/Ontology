{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text-to-Knowledge graphğŸ”Š with langchain\n",
        "\n",
        "- langchain : https://python.langchain.com/docs/get_started/introduction"
      ],
      "metadata": {
        "id": "sz49bNIQODlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ğŸ”¨"
      ],
      "metadata": {
        "id": "sCEITDIqMJyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVi5dLOPMG7D",
        "outputId": "6b32409c-03ef-4dd6-fbca-446cbd9b31f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.346-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-core<0.1,>=0.0.10 (from langchain)\n",
            "  Downloading langchain_core-0.0.10-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.346 langchain-core-0.0.10 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPENAI API í™˜ê²½ ì„¤ì •ğŸ”‘"
      ],
      "metadata": {
        "id": "29Z_YwkoOKVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import os\n",
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# API key\n",
        "openai.api_key = \"OPENAI_API_KEY\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ],
      "metadata": {
        "id": "LsaUnIBionA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text-to-tripleğŸ‡"
      ],
      "metadata": {
        "id": "fHA3BenrOknJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from langchain.indexes import GraphIndexCreator\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "#graph index creator ì •ì˜\n",
        "index_creator = GraphIndexCreator(llm=OpenAI(temperature=0))\n",
        "\n",
        "#text-to-triple\n",
        "graph = index_creator.from_text(\"\"\"Microsoft Invests $10 Billion in ChatGPT Maker OpenAI.\"\"\")\n",
        "print(graph.get_triples())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk9Ofkwjn226",
        "outputId": "9aa4aac3-7e95-4254-a340-72a78c065f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Microsoft', '$10 Billion', 'invests'), ('Microsoft', 'ChatGPT Maker OpenAI', 'invests in')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from langchain.graphs.networkx_graph import KnowledgeTriple\n",
        "\n",
        "#triple ì¶”ê°€í•˜ê¸°\n",
        "graph.add_triple(KnowledgeTriple('Google', '$300 Million', 'invests'))\n",
        "graph.add_triple(KnowledgeTriple('Google', 'Anthropic', 'invests in'))"
      ],
      "metadata": {
        "id": "4NErRPotpF7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### text fileë¡œ triple ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "8qEIfaiyPbj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from langchain.indexes import GraphIndexCreator\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "#graph index creator ì •ì˜\n",
        "index_creator = GraphIndexCreator(llm=OpenAI(temperature=0))\n",
        "\n",
        "#ë¬¸ì„œ ë¶ˆëŸ¬ì™€ì„œ triple ë§Œë“¤ê¸°\n",
        "with open('/content/ChatGPT.txt', 'r') as file:\n",
        "  files = file.read()\n",
        "  #text = \"\\n\".join(files.split(\"\\n\\n\")[105:108])\n",
        "  graph = index_creator.from_text(files)\n",
        "\n",
        "  print(graph.get_triples())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF_ieqawq_Br",
        "outputId": "61a87999-bffd-43b1-a9d2-f1d32248721c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ChatGPT', 'chatbot', 'is a'), ('ChatGPT', 'OpenAI', 'is developed by'), ('ChatGPT', 'GPT-3.5', 'is built upon'), ('ChatGPT', 'GPT-4', 'is built upon'), ('ChatGPT', 'conversational applications', 'is fine-tuned for'), ('ChatGPT', 'a freely available research preview', 'is released as'), ('ChatGPT', 'a freemium model', 'is operated on'), ('ChatGPT', 'GPT-3.5-based version', 'allows users on its free tier to access'), ('ChatGPT', 'paid subscribers', 'provides more advanced GPT-4-based version to'), ('ChatGPT', \"OpenAI's valuation growing to $29 billion)<\", 'contributes to')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ìì—°ì–´ë¡œ knowledge graphì— ì§ˆë¬¸í•˜ê¸°ğŸ¤"
      ],
      "metadata": {
        "id": "jl6h8dOAOppf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from langchain.chains import GraphQAChain\n",
        "\n",
        "# graphQAchain ì •ì˜\n",
        "chain = GraphQAChain.from_llm(OpenAI(temperature=0), graph=graph, verbose=True)\n",
        "\n",
        "#ìì—°ì–´ ì¿¼ë¦¬\n",
        "chain.run(\"When ChatGPT did start?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "ta8H2aSPugaK",
        "outputId": "d2ed60e2-ea4a-482e-dc7c-11d5adf6b270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphQAChain chain...\u001b[0m\n",
            "Entities Extracted:\n",
            "\u001b[32;1m\u001b[1;3m ChatGPT\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3mChatGPT is a chatbot\n",
            "ChatGPT is developed by OpenAI\n",
            "ChatGPT is built upon GPT-3.5\n",
            "ChatGPT is built upon GPT-4\n",
            "ChatGPT is fine-tuned for conversational applications\n",
            "ChatGPT is released as a freely available research preview\n",
            "ChatGPT is operated on a freemium model\n",
            "ChatGPT allows users on its free tier to access GPT-3.5-based version\n",
            "ChatGPT provides more advanced GPT-4-based version to paid subscribers\n",
            "ChatGPT contributes to OpenAI's valuation growing to $29 billion)<\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ChatGPT was released as a freely available research preview.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wfLIOB3kUfv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}